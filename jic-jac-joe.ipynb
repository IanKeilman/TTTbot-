{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "# Define winning combinations\n",
    "winning_combos = [\n",
    "    (0, 1, 2),  # Rows\n",
    "    (3, 4, 5),\n",
    "    (6, 7, 8),\n",
    "    (0, 3, 6),  # Columns\n",
    "    (1, 4, 7),\n",
    "    (2, 5, 8),\n",
    "    (0, 4, 8),  # Diagonals\n",
    "    (2, 4, 6)\n",
    "]\n",
    "\n",
    "def check_winner(board, player):\n",
    "    \"\"\"Check if the given player has won.\"\"\"\n",
    "    for combo in winning_combos:\n",
    "        if all(board[i] == player for i in combo):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def is_draw(board):\n",
    "    \"\"\"Check if the game is a draw.\"\"\"\n",
    "    return ' ' not in board\n",
    "\n",
    "def available_moves(board):\n",
    "    \"\"\"Return a list of available moves.\"\"\"\n",
    "    return [i for i, spot in enumerate(board) if spot == ' ']\n",
    "\n",
    "def print_board(board):\n",
    "    \"\"\"Print the current board state.\"\"\"\n",
    "    print(f\"{board[0]} | {board[1]} | {board[2]}\")\n",
    "    print(\"--+---+--\")\n",
    "    print(f\"{board[3]} | {board[4]} | {board[5]}\")\n",
    "    print(\"--+---+--\")\n",
    "    print(f\"{board[6]} | {board[7]} | {board[8]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete after 100000 episodes.\n",
      "State: (' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' '), X win rate: 0.58, O win rate: 0.29, Draw rate: 0.13\n",
      "State: (' ', ' ', 'X', ' ', ' ', ' ', ' ', ' ', ' '), X win rate: 0.61, O win rate: 0.26, Draw rate: 0.13\n",
      "State: (' ', 'O', 'X', ' ', ' ', ' ', ' ', ' ', ' '), X win rate: 0.66, O win rate: 0.17, Draw rate: 0.17\n",
      "State: (' ', 'O', 'X', ' ', ' ', ' ', ' ', 'X', ' '), X win rate: 0.61, O win rate: 0.12, Draw rate: 0.28\n",
      "State: (' ', 'O', 'X', ' ', ' ', ' ', 'O', 'X', ' '), X win rate: 0.38, O win rate: 0.06, Draw rate: 0.56\n",
      "State: (' ', 'O', 'X', ' ', ' ', 'X', 'O', 'X', ' '), X win rate: 0.49, O win rate: 0.11, Draw rate: 0.41\n",
      "State: (' ', 'O', 'X', ' ', ' ', 'X', 'O', 'X', 'O'), X win rate: 0.25, O win rate: 0.00, Draw rate: 0.75\n",
      "State: (' ', 'O', 'X', 'X', ' ', 'X', 'O', 'X', 'O'), X win rate: 0.54, O win rate: 0.00, Draw rate: 0.46\n",
      "State: ('O', 'O', 'X', 'X', ' ', 'X', 'O', 'X', 'O'), X win rate: 1.00, O win rate: 0.00, Draw rate: 0.00\n",
      "State: (' ', ' ', ' ', ' ', ' ', 'X', ' ', ' ', ' '), X win rate: 0.54, O win rate: 0.33, Draw rate: 0.13\n"
     ]
    }
   ],
   "source": [
    "state_statistics = {}\n",
    "\n",
    "def update_state_statistics(state, winner):\n",
    "    \"\"\"Update the statistics for a given game state.\"\"\"\n",
    "    if state not in state_statistics:\n",
    "        state_statistics[state] = [0, 0, 0, 0]  # [games_played, x_wins, o_wins, draws]\n",
    "    \n",
    "    state_statistics[state][0] += 1  # Increment games played\n",
    "    \n",
    "    if winner == 'X':\n",
    "        state_statistics[state][1] += 1  # Increment X wins\n",
    "    elif winner == 'O':\n",
    "        state_statistics[state][2] += 1  # Increment O wins\n",
    "    elif winner == 'draw':\n",
    "        state_statistics[state][3] += 1  # Increment draws\n",
    "\n",
    "def simulate_game(agent, verbose=False):\n",
    "    \"\"\"Simulate a single game and update state statistics.\"\"\"\n",
    "    board = [' '] * 9\n",
    "    current_player = 'X'\n",
    "    state_action_history = []\n",
    "    \n",
    "    while True:\n",
    "        state = tuple(board)\n",
    "        action = agent.choose_action(board, current_player)\n",
    "        board[action] = current_player\n",
    "        next_state = tuple(board)\n",
    "        state_action_history.append((state, action, current_player))\n",
    "\n",
    "        if check_winner(board, current_player):\n",
    "            winner = current_player\n",
    "            for state, action, player in state_action_history:\n",
    "                update_state_statistics(state, winner=winner)\n",
    "            break\n",
    "        elif is_draw(board):\n",
    "            for state, action, player in state_action_history:\n",
    "                update_state_statistics(state, winner='draw')\n",
    "            break\n",
    "        else:\n",
    "            current_player = 'O' if current_player == 'X' else 'X'\n",
    "    \n",
    "    if verbose:\n",
    "        print_board(board)\n",
    "\n",
    "def train_agent(agent, episodes=10000):\n",
    "    \"\"\"Train the agent by simulating games and updating state statistics.\"\"\"\n",
    "    for episode in range(episodes):\n",
    "        simulate_game(agent)\n",
    "    print(f\"Training complete after {episodes} episodes.\")\n",
    "\n",
    "def calculate_win_draw_rates():\n",
    "    \"\"\"Calculate the win and draw rates for all encountered game states.\"\"\"\n",
    "    win_draw_rates = {}\n",
    "    for state, stats in state_statistics.items():\n",
    "        games_played, x_wins, o_wins, draws = stats\n",
    "        if games_played > 0:\n",
    "            x_win_rate = x_wins / games_played\n",
    "            o_win_rate = o_wins / games_played\n",
    "            draw_rate = draws / games_played\n",
    "            win_draw_rates[state] = {\n",
    "                'X_win_rate': x_win_rate,\n",
    "                'O_win_rate': o_win_rate,\n",
    "                'draw_rate': draw_rate\n",
    "            }\n",
    "    return win_draw_rates\n",
    "\n",
    "# Example of an agent with random actions (you can replace this with your agent logic)\n",
    "class RandomAgent:\n",
    "    def choose_action(self, board, player):\n",
    "        \"\"\"Randomly choose an available action.\"\"\"\n",
    "        return random.choice(available_moves(board))\n",
    "\n",
    "# Train the agent and collect state statistics\n",
    "agent = RandomAgent()\n",
    "train_agent(agent, episodes=100000)\n",
    "\n",
    "# Calculate win and draw rates from the simulations\n",
    "win_draw_rates = calculate_win_draw_rates()\n",
    "\n",
    "# Display some sample win and draw rates (you can analyze them further or store them)\n",
    "for state, rates in list(win_draw_rates.items())[:10]:  # Display first 10 states and their win/draw rates\n",
    "    print(f\"State: {state}, X win rate: {rates['X_win_rate']:.2f}, O win rate: {rates['O_win_rate']:.2f}, Draw rate: {rates['draw_rate']:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete after 10000 episodes.\n",
      "X | O | X\n",
      "--+---+--\n",
      "X | X | O\n",
      "--+---+--\n",
      "O | X | O\n"
     ]
    }
   ],
   "source": [
    "def combined_heuristic(state, action, current_player, next_player):\n",
    "    \"\"\"Calculate the combined value of a move based on win/loss rates.\"\"\"\n",
    "    # Get the resulting state after the action is taken\n",
    "    board = list(state)\n",
    "    board[action] = current_player\n",
    "    next_state = tuple(board)\n",
    "    \n",
    "    # Get win and loss rates for current player and opponent\n",
    "    win_rate_current = win_draw_rates.get(next_state, {}).get(f'{current_player}_win_rate', 0)\n",
    "    win_rate_opponent = win_draw_rates.get(next_state, {}).get(f'{next_player}_win_rate', 0)\n",
    "    \n",
    "    # You can also consider draw rate if needed\n",
    "    draw_rate = win_draw_rates.get(next_state, {}).get('draw_rate', 0)\n",
    "    \n",
    "    # Weights for win, opponent win (loss prevention), and draw\n",
    "    alpha = 1.0  # Weight for maximizing your win\n",
    "    beta = 0.1  # Weight for minimizing opponent win\n",
    "    gamma = 0.1  # Weight for considering draws (tune as needed)\n",
    "    \n",
    "    # Calculate the combined heuristic value\n",
    "    value = alpha * win_rate_current - beta * win_rate_opponent + gamma * draw_rate\n",
    "    return value\n",
    "\n",
    "def choose_best_action(board, current_player, next_player):\n",
    "    \"\"\"Choose the best action based on combined win/loss minimization strategy.\"\"\"\n",
    "    available_actions = available_moves(board)\n",
    "    best_value = -float('inf')\n",
    "    best_action = None\n",
    "    \n",
    "    for action in available_actions:\n",
    "        value = combined_heuristic(tuple(board), action, current_player, next_player)\n",
    "        if value > best_value:\n",
    "            best_value = value\n",
    "            best_action = action\n",
    "    \n",
    "    return best_action\n",
    "\n",
    "# Example usage in a game\n",
    "class SmartAgent:\n",
    "    def choose_action(self, board, player):\n",
    "        \"\"\"Choose an action based on the combined heuristic strategy.\"\"\"\n",
    "        next_player = 'O' if player == 'X' else 'X'\n",
    "        return choose_best_action(board, player, next_player)\n",
    "\n",
    "# Train the smart agent\n",
    "smart_agent = SmartAgent()\n",
    "train_agent(smart_agent, episodes=10000)\n",
    "\n",
    "# Simulate a game\n",
    "simulate_game(smart_agent, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete after 10000 episodes.\n",
      "  |   |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "SmartAgent (X) is thinking...\n",
      "SmartAgent (X) played at position 4\n",
      "  |   |  \n",
      "--+---+--\n",
      "  | X |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "  | O |  \n",
      "--+---+--\n",
      "  | X |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "SmartAgent (X) is thinking...\n",
      "SmartAgent (X) played at position 2\n",
      "  | O | X\n",
      "--+---+--\n",
      "  | X |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "O | O | X\n",
      "--+---+--\n",
      "  | X |  \n",
      "--+---+--\n",
      "  |   |  \n",
      "SmartAgent (X) is thinking...\n",
      "SmartAgent (X) played at position 5\n",
      "O | O | X\n",
      "--+---+--\n",
      "  | X | X\n",
      "--+---+--\n",
      "  |   |  \n",
      "O | O | X\n",
      "--+---+--\n",
      "  | X | X\n",
      "--+---+--\n",
      "O |   |  \n",
      "SmartAgent (X) is thinking...\n",
      "SmartAgent (X) played at position 7\n",
      "O | O | X\n",
      "--+---+--\n",
      "  | X | X\n",
      "--+---+--\n",
      "O | X |  \n",
      "O | O | X\n",
      "--+---+--\n",
      "O | X | X\n",
      "--+---+--\n",
      "O | X |  \n",
      "Player O wins!\n"
     ]
    }
   ],
   "source": [
    "def play_game():\n",
    "    \"\"\"Allow a human player to play against the trained SmartAgent.\"\"\"\n",
    "    board = [' '] * 9\n",
    "    human_player = input(\"Choose your player (X or O): \").upper()\n",
    "    \n",
    "    if human_player not in ['X', 'O']:\n",
    "        print(\"Invalid choice. Defaulting to X.\")\n",
    "        human_player = 'X'\n",
    "    \n",
    "    ai_player = 'O' if human_player == 'X' else 'X'\n",
    "    current_player = 'X'  # X always starts the game\n",
    "    smart_agent = SmartAgent()\n",
    "\n",
    "    print_board(board)\n",
    "\n",
    "    while True:\n",
    "        if current_player == human_player:\n",
    "            # Human's turn\n",
    "            available = available_moves(board)\n",
    "            move = None\n",
    "            while move not in available:\n",
    "                try:\n",
    "                    move = int(input(f\"Your move (choose from {available}): \"))\n",
    "                    if move not in available:\n",
    "                        print(\"Invalid move. Try again.\")\n",
    "                except ValueError:\n",
    "                    print(\"Please enter a valid number.\")\n",
    "            board[move] = human_player\n",
    "        else:\n",
    "            # Smart agent's turn\n",
    "            print(f\"SmartAgent ({ai_player}) is thinking...\")\n",
    "            move = smart_agent.choose_action(board, ai_player)\n",
    "            board[move] = ai_player\n",
    "            print(f\"SmartAgent ({ai_player}) played at position {move}\")\n",
    "\n",
    "        print_board(board)\n",
    "\n",
    "        # Check for winner or draw\n",
    "        if check_winner(board, current_player):\n",
    "            print(f\"Player {current_player} wins!\")\n",
    "            break\n",
    "        elif is_draw(board):\n",
    "            print(\"It's a draw!\")\n",
    "            break\n",
    "\n",
    "        # Switch players\n",
    "        current_player = 'O' if current_player == 'X' else 'X'\n",
    "\n",
    "# Train the SmartAgent with 10,000 games\n",
    "agent = SmartAgent()\n",
    "train_agent(agent, episodes=10000)\n",
    "\n",
    "# Now play against the trained agent\n",
    "play_game()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
